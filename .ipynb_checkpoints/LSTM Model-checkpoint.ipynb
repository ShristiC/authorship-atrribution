{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0   author  label  \\\n",
      "0               0   austen      0   \n",
      "1               1   austen      0   \n",
      "2               2   austen      0   \n",
      "3               3   austen      0   \n",
      "4               4   austen      0   \n",
      "...           ...      ...    ...   \n",
      "18888       18888  whitman     11   \n",
      "18889       18889  whitman     11   \n",
      "18890       18890  whitman     11   \n",
      "18891       18891  whitman     11   \n",
      "18892       18892  whitman     11   \n",
      "\n",
      "                                                    text  \n",
      "0      [Emma Jane Austen 1816] VOLUME I CHAPTER I Emm...  \n",
      "1      Even Miss Taylor ceased hold nominal office go...  \n",
      "2      It wedding-day beloved friend Emma sat mournfu...  \n",
      "3      The want Miss Taylor felt hour day.She recalle...  \n",
      "4      She dearly loved father, companion her.He meet...  \n",
      "...                                                  ...  \n",
      "18888  Mirages More experiences sights, stranger, you...  \n",
      "18889  The Unexpress'd How dare it?After cycles, poem...  \n",
      "18890  More evolutionary, vast, puzzling, O soul!More...  \n",
      "18891  Farewell dear mate, dear love!I'm going away, ...  \n",
      "18892  May-be mortal knob undoing, turning--so finall...  \n",
      "\n",
      "[18893 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def data_retrieval(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    return df\n",
    "\n",
    "df = data_retrieval('gutenberg_expanded.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# determining average word count per text\n",
    "word_count = []\n",
    "for i in df['text'].values:\n",
    "    word_count.append(len(i.split()))\n",
    "word_count = np.array(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(var):\n",
    "    \"\"\"Print summary statistics for a variable of interest.\n",
    "    \n",
    "    Args:\n",
    "    var: array. Numpy array containing values for the variable of interest.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"Min:\", np.min(var))\n",
    "    print(\"Max:\", np.max(var))\n",
    "    print(\"Mean:\", np.mean(var))\n",
    "    print(\"Median\", np.median(var))\n",
    "    print(\"1st percentile\", np.percentile(var, 1))\n",
    "    print(\"95th percentile\", np.percentile(var, 95))\n",
    "    print(\"99th percentile\", np.percentile(var, 99))\n",
    "    print(\"99.5th Percentile\", np.percentile(var, 99.5))\n",
    "    print(\"99.9th Percentile\", np.percentile(var, 99.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count statistics\n",
      "Min: 1\n",
      "Max: 875\n",
      "Mean: 55.006351558778384\n",
      "Median 49.0\n",
      "1st percentile 8.0\n",
      "95th percentile 115.0\n",
      "99th percentile 181.0799999999981\n",
      "99.5th Percentile 221.0\n",
      "99.9th Percentile 319.0800000000381\n"
     ]
    }
   ],
   "source": [
    "print(\"Word count statistics\")\n",
    "get_stats(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot word count distribution\n",
    "sns.distplot(word_count, kde = False, bins = 70, color = 'blue').set_title(\"Word Count Distribution\")\n",
    "plt.xlabel('Excerpt Length (Words)')\n",
    "plt.ylabel('Count')\n",
    "plt.xlim(0, 500)\n",
    "plt.savefig(\"word_count.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15114,) (15114,)\n",
      "(1889,) (1889,)\n",
      "(1890,) (1890,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "text = df['text'].values\n",
    "labels = df['label'].values\n",
    "# splitting data into 80-20 for training and testing\n",
    "text_train, text_test_val, label_train, label_test_val = train_test_split(text,labels, test_size = 0.2, random_state = 42)\n",
    "# splitting testing data into 50-50 for testing and validation\n",
    "text_test, text_val, label_test, label_val = train_test_split(text_test_val, label_test_val, test_size=.5, random_state=42)\n",
    "print(text_train.shape, label_train.shape)\n",
    "print(text_test.shape, label_test.shape)\n",
    "print(text_val.shape, label_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing\n",
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "# removing stop words\n",
    "def remove_stop_words_preprocessing(text_values):\n",
    "    for i in range(len(text_values)):\n",
    "        text_values[i] = remove_stopwords(text_values[i].lower())\n",
    "    return text_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embeddings\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def word_embeddings(text_values):\n",
    "    tokenizer = Tokenizer(num_words=5000, oov_token=\"UNK\")\n",
    "    tokenizer.fit_on_texts(text_values)\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41126 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Removing the stop words\n",
    "X = remove_stop_words_preprocessing(text_train)\n",
    "X_val_text = remove_stop_words_preprocessing(text_val)\n",
    "X_test_text = remove_stop_words_preprocessing(text_test)\n",
    "\n",
    "# Creating a tokenization\n",
    "tokenizer = word_embeddings(X)\n",
    "\n",
    "# Tokenizing the sentences\n",
    "X_train = tokenizer.texts_to_sequences(X)\n",
    "X_val = tokenizer.texts_to_sequences(X_val_text)\n",
    "X_test = tokenizer.texts_to_sequences(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41127\n"
     ]
    }
   ],
   "source": [
    "# vocab size\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (15114, 80)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_sequence_length = 80\n",
    "X_train = pad_sequences(X_train, padding=\"post\", maxlen=max_sequence_length)\n",
    "X_val = pad_sequences(X_val, padding=\"post\", maxlen=max_sequence_length)\n",
    "X_test = pad_sequences(X_test, padding=\"post\", maxlen=max_sequence_length)\n",
    "print('Shape of data tensor:', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor:  (15114, 12)\n"
     ]
    }
   ],
   "source": [
    "Y_train = pd.get_dummies(label_train).values\n",
    "Y_val = pd.get_dummies(label_val).values\n",
    "Y_test = pd.get_dummies(label_test).values\n",
    "print('Shape of label tensor: ', Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 80, 50)            2056350   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 80, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                1212      \n",
      "=================================================================\n",
      "Total params: 2,117,962\n",
      "Trainable params: 2,117,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                   output_dim=embedding_dim,\n",
    "                  input_length=max_sequence_length))\n",
    "model.add(layers.SpatialDropout1D(0.2))\n",
    "\n",
    "model.add(layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(layers.Dense(12, activation='softmax'))\n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15114 samples, validate on 1890 samples\n",
      "Epoch 1/10\n",
      "15114/15114 [==============================] - 106s 7ms/step - loss: 1.6846 - accuracy: 0.4172 - val_loss: 1.4291 - val_accuracy: 0.4857\n",
      "Epoch 2/10\n",
      "15114/15114 [==============================] - 95s 6ms/step - loss: 1.4188 - accuracy: 0.5237 - val_loss: 1.2486 - val_accuracy: 0.6201\n",
      "Epoch 3/10\n",
      "15114/15114 [==============================] - 93s 6ms/step - loss: 1.4380 - accuracy: 0.5251 - val_loss: 1.1121 - val_accuracy: 0.6286\n",
      "Epoch 4/10\n",
      "15114/15114 [==============================] - 94s 6ms/step - loss: 1.0165 - accuracy: 0.6350 - val_loss: 0.8417 - val_accuracy: 0.6947\n",
      "Epoch 5/10\n",
      "15114/15114 [==============================] - 93s 6ms/step - loss: 0.8593 - accuracy: 0.6919 - val_loss: 0.7529 - val_accuracy: 0.7243\n",
      "Epoch 6/10\n",
      "15114/15114 [==============================] - 97s 6ms/step - loss: 0.7233 - accuracy: 0.7436 - val_loss: 0.6622 - val_accuracy: 0.7667\n",
      "Epoch 7/10\n",
      "15114/15114 [==============================] - 96s 6ms/step - loss: 0.5982 - accuracy: 0.7990 - val_loss: 0.5734 - val_accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "15114/15114 [==============================] - 96s 6ms/step - loss: 0.4710 - accuracy: 0.8442 - val_loss: 0.4574 - val_accuracy: 0.8497\n",
      "Epoch 9/10\n",
      "15114/15114 [==============================] - 103s 7ms/step - loss: 0.3452 - accuracy: 0.8886 - val_loss: 0.3379 - val_accuracy: 0.8921\n",
      "Epoch 10/10\n",
      "15114/15114 [==============================] - 98s 7ms/step - loss: 0.2392 - accuracy: 0.9245 - val_loss: 0.2916 - val_accuracy: 0.9090\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "                    epochs=10, \n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1889/1889 [==============================] - 2s 861us/step\n",
      "[[285   0   0   0   0   0   3  11   1   0   1   0]\n",
      " [  0 613   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   3   1   2]\n",
      " [  0   0   0  34   0   4   3  13   2   0   2   0]\n",
      " [  0   0   0   1   2  13   1   1   0   0   0   0]\n",
      " [  0   0   0   0   2  21   3   4   0   0   1   0]\n",
      " [  0   0   0   3   0   0 215  11  14   0   1   1]\n",
      " [  6   0   0   1   0   0   3 193   2   0   0   0]\n",
      " [  0   0   0   1   0   0   8   1 192   0   1   3]\n",
      " [  0   0   0   0   0   0   0   0   0  23   0   9]\n",
      " [  0   1   0   0   0   0   0   0   0   0  95   0]\n",
      " [  0   0   0   0   0   0   1   1  20   3   2  50]]\n",
      "Test set\n",
      "  Loss: 0.267\n",
      "  Accuracy: 0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "accuracy = model.evaluate(X_test, Y_test)\n",
    "prediction = model.predict(X_test)\n",
    "confusion_matrix = confusion_matrix(Y_test.argmax(axis=1), prediction.argmax(axis=1))\n",
    "print(confusion_matrix)\n",
    "\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accuracy[0],accuracy[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Against Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial / Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ngram Distribution Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
