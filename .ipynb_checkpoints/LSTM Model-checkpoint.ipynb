{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0   author  label  \\\n",
      "0               0   austen      0   \n",
      "1               1   austen      0   \n",
      "2               2   austen      0   \n",
      "3               3   austen      0   \n",
      "4               4   austen      0   \n",
      "...           ...      ...    ...   \n",
      "18888       18888  whitman     11   \n",
      "18889       18889  whitman     11   \n",
      "18890       18890  whitman     11   \n",
      "18891       18891  whitman     11   \n",
      "18892       18892  whitman     11   \n",
      "\n",
      "                                                    text  \n",
      "0      [Emma Jane Austen 1816] VOLUME I CHAPTER I Emm...  \n",
      "1      Even Miss Taylor ceased hold nominal office go...  \n",
      "2      It wedding-day beloved friend Emma sat mournfu...  \n",
      "3      The want Miss Taylor felt hour day.She recalle...  \n",
      "4      She dearly loved father, companion her.He meet...  \n",
      "...                                                  ...  \n",
      "18888  Mirages More experiences sights, stranger, you...  \n",
      "18889  The Unexpress'd How dare it?After cycles, poem...  \n",
      "18890  More evolutionary, vast, puzzling, O soul!More...  \n",
      "18891  Farewell dear mate, dear love!I'm going away, ...  \n",
      "18892  May-be mortal knob undoing, turning--so finall...  \n",
      "\n",
      "[18893 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "def data_retrieval(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    return df\n",
    "\n",
    "df = data_retrieval('gutenberg_expanded.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# determining average word count per text\n",
    "word_count = []\n",
    "for i in df['text'].values:\n",
    "    word_count.append(len(i.split()))\n",
    "word_count = np.array(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(var):\n",
    "    \"\"\"Print summary statistics for a variable of interest.\n",
    "    \n",
    "    Args:\n",
    "    var: array. Numpy array containing values for the variable of interest.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"Min:\", np.min(var))\n",
    "    print(\"Max:\", np.max(var))\n",
    "    print(\"Mean:\", np.mean(var))\n",
    "    print(\"Median\", np.median(var))\n",
    "    print(\"1st percentile\", np.percentile(var, 1))\n",
    "    print(\"95th percentile\", np.percentile(var, 95))\n",
    "    print(\"99th percentile\", np.percentile(var, 99))\n",
    "    print(\"99.5th Percentile\", np.percentile(var, 99.5))\n",
    "    print(\"99.9th Percentile\", np.percentile(var, 99.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count statistics\n",
      "Min: 1\n",
      "Max: 875\n",
      "Mean: 55.006351558778384\n",
      "Median 49.0\n",
      "1st percentile 8.0\n",
      "95th percentile 115.0\n",
      "99th percentile 181.0799999999981\n",
      "99.5th Percentile 221.0\n",
      "99.9th Percentile 319.0800000000381\n"
     ]
    }
   ],
   "source": [
    "print(\"Word count statistics\")\n",
    "get_stats(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot word count distribution\n",
    "sns.distplot(word_count, kde = False, bins = 70, color = 'blue').set_title(\"Word Count Distribution\")\n",
    "plt.xlabel('Excerpt Length (Words)')\n",
    "plt.ylabel('Count')\n",
    "plt.xlim(0, 500)\n",
    "plt.savefig(\"word_count.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15114,) (15114,)\n",
      "(1889,) (1889,)\n",
      "(1890,) (1890,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "text = df['text'].values\n",
    "labels = df['label'].values\n",
    "# splitting data into 80-20 for training and testing\n",
    "text_train, text_test_val, label_train, label_test_val = train_test_split(text,labels, test_size = 0.2, random_state = 42)\n",
    "# splitting testing data into 50-50 for testing and validation\n",
    "text_test, text_val, label_test, label_val = train_test_split(text_test_val, label_test_val, test_size=.5, random_state=42)\n",
    "print(text_train.shape, label_train.shape)\n",
    "print(text_test.shape, label_test.shape)\n",
    "print(text_val.shape, label_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing\n",
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "# removing stop words\n",
    "def remove_stop_words_preprocessing(text_values):\n",
    "    for i in range(len(text_values)):\n",
    "        text_values[i] = remove_stopwords(text_values[i].lower())\n",
    "    return text_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embeddings\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def word_embeddings(text_values):\n",
    "    tokenizer = Tokenizer(num_words=5000, oov_token=\"UNK\")\n",
    "    tokenizer.fit_on_texts(text_values)\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41126 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Removing the stop words\n",
    "X = remove_stop_words_preprocessing(text_train)\n",
    "X_val_text = remove_stop_words_preprocessing(text_val)\n",
    "X_test_text = remove_stop_words_preprocessing(text_test)\n",
    "\n",
    "# Creating a tokenization\n",
    "tokenizer = word_embeddings(X)\n",
    "\n",
    "# Tokenizing the sentences\n",
    "X_train = tokenizer.texts_to_sequences(X)\n",
    "X_val = tokenizer.texts_to_sequences(X_val_text)\n",
    "X_test = tokenizer.texts_to_sequences(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41127\n"
     ]
    }
   ],
   "source": [
    "# vocab size\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (15114, 80)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_sequence_length = 80\n",
    "X_train = pad_sequences(X_train, padding=\"post\", maxlen=max_sequence_length)\n",
    "X_val = pad_sequences(X_val, padding=\"post\", maxlen=max_sequence_length)\n",
    "X_test = pad_sequences(X_test, padding=\"post\", maxlen=max_sequence_length)\n",
    "print('Shape of data tensor:', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor:  (15114, 12)\n"
     ]
    }
   ],
   "source": [
    "Y_train = pd.get_dummies(label_train).values\n",
    "Y_val = pd.get_dummies(label_val).values\n",
    "Y_test = pd.get_dummies(label_test).values\n",
    "print('Shape of label tensor: ', Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "pretext_model = load_model(\"pretext_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 80, 50)            1940100   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 80, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 505       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                72        \n",
      "=================================================================\n",
      "Total params: 2,001,077\n",
      "Trainable params: 2,001,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "\n",
    "pretext_model.add(layers.Dense(12, activation='softmax'))\n",
    "pretext_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "pretext_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15114 samples, validate on 1890 samples\n",
      "Epoch 1/50\n",
      "15114/15114 [==============================] - 192s 13ms/step - loss: 2.1324 - accuracy: 0.2682 - val_loss: 1.9733 - val_accuracy: 0.3725\n",
      "Epoch 2/50\n",
      "15114/15114 [==============================] - 177s 12ms/step - loss: 1.7836 - accuracy: 0.4389 - val_loss: 1.6502 - val_accuracy: 0.4725\n",
      "Epoch 3/50\n",
      "15114/15114 [==============================] - 180s 12ms/step - loss: 1.6008 - accuracy: 0.4676 - val_loss: 1.5225 - val_accuracy: 0.4878\n",
      "Epoch 4/50\n",
      "15114/15114 [==============================] - 152s 10ms/step - loss: 1.5095 - accuracy: 0.4749 - val_loss: 1.4657 - val_accuracy: 0.4889\n",
      "Epoch 5/50\n",
      "15114/15114 [==============================] - 176s 12ms/step - loss: 1.4578 - accuracy: 0.4802 - val_loss: 1.4336 - val_accuracy: 0.4899\n",
      "Epoch 6/50\n",
      "15114/15114 [==============================] - 215s 14ms/step - loss: 1.4362 - accuracy: 0.4828 - val_loss: 1.4028 - val_accuracy: 0.4942\n",
      "Epoch 7/50\n",
      "15114/15114 [==============================] - 216s 14ms/step - loss: 1.3914 - accuracy: 0.4911 - val_loss: 1.3367 - val_accuracy: 0.5058\n",
      "Epoch 8/50\n",
      "15114/15114 [==============================] - 217s 14ms/step - loss: 1.2846 - accuracy: 0.5736 - val_loss: 1.1722 - val_accuracy: 0.6196\n",
      "Epoch 9/50\n",
      "15114/15114 [==============================] - 216s 14ms/step - loss: 1.1001 - accuracy: 0.6496 - val_loss: 1.0248 - val_accuracy: 0.6603\n",
      "Epoch 10/50\n",
      "15114/15114 [==============================] - 217s 14ms/step - loss: 0.9742 - accuracy: 0.6804 - val_loss: 0.9361 - val_accuracy: 0.6730\n",
      "Epoch 11/50\n",
      "15114/15114 [==============================] - 246s 16ms/step - loss: 0.8875 - accuracy: 0.6941 - val_loss: 0.8833 - val_accuracy: 0.6799\n",
      "Epoch 12/50\n",
      "15114/15114 [==============================] - 220s 15ms/step - loss: 0.8220 - accuracy: 0.7040 - val_loss: 0.8302 - val_accuracy: 0.6889\n",
      "Epoch 13/50\n",
      "15114/15114 [==============================] - 239s 16ms/step - loss: 0.7619 - accuracy: 0.7173 - val_loss: 0.7863 - val_accuracy: 0.7063\n",
      "Epoch 14/50\n",
      "15114/15114 [==============================] - 212s 14ms/step - loss: 0.7007 - accuracy: 0.7291 - val_loss: 0.7434 - val_accuracy: 0.7164\n",
      "Epoch 15/50\n",
      "15114/15114 [==============================] - 214s 14ms/step - loss: 0.6601 - accuracy: 0.7365 - val_loss: 0.7043 - val_accuracy: 0.7180\n",
      "Epoch 16/50\n",
      "15114/15114 [==============================] - 197s 13ms/step - loss: 0.6265 - accuracy: 0.7406 - val_loss: 0.7047 - val_accuracy: 0.7175\n",
      "Epoch 17/50\n",
      "15114/15114 [==============================] - 204s 13ms/step - loss: 0.6049 - accuracy: 0.7447 - val_loss: 0.6927 - val_accuracy: 0.7185\n",
      "Epoch 18/50\n",
      "15114/15114 [==============================] - 186s 12ms/step - loss: 0.5816 - accuracy: 0.7475 - val_loss: 0.6797 - val_accuracy: 0.7212\n",
      "Epoch 19/50\n",
      "15114/15114 [==============================] - 184s 12ms/step - loss: 0.5702 - accuracy: 0.7480 - val_loss: 0.6670 - val_accuracy: 0.7201\n",
      "Epoch 20/50\n",
      "15114/15114 [==============================] - 193s 13ms/step - loss: 0.5580 - accuracy: 0.7506 - val_loss: 0.6591 - val_accuracy: 0.7233\n",
      "Epoch 21/50\n",
      "15114/15114 [==============================] - 187s 12ms/step - loss: 0.5481 - accuracy: 0.7525 - val_loss: 0.6596 - val_accuracy: 0.7228\n",
      "Epoch 22/50\n",
      "15114/15114 [==============================] - 187s 12ms/step - loss: 0.5405 - accuracy: 0.7532 - val_loss: 0.6577 - val_accuracy: 0.7249\n",
      "Epoch 23/50\n",
      "15114/15114 [==============================] - 182s 12ms/step - loss: 0.5324 - accuracy: 0.7539 - val_loss: 0.6558 - val_accuracy: 0.7259\n",
      "Epoch 24/50\n",
      "15114/15114 [==============================] - 180s 12ms/step - loss: 0.5213 - accuracy: 0.7574 - val_loss: 0.6480 - val_accuracy: 0.7206\n",
      "Epoch 25/50\n",
      "15114/15114 [==============================] - 173s 11ms/step - loss: 0.5098 - accuracy: 0.7613 - val_loss: 0.6390 - val_accuracy: 0.7243\n",
      "Epoch 26/50\n",
      "15114/15114 [==============================] - 172s 11ms/step - loss: 0.4936 - accuracy: 0.7701 - val_loss: 0.6326 - val_accuracy: 0.7349\n",
      "Epoch 27/50\n",
      "15114/15114 [==============================] - 172s 11ms/step - loss: 0.4792 - accuracy: 0.7772 - val_loss: 0.6182 - val_accuracy: 0.7466\n",
      "Epoch 28/50\n",
      "15114/15114 [==============================] - 172s 11ms/step - loss: 0.4636 - accuracy: 0.7920 - val_loss: 0.6116 - val_accuracy: 0.7566\n",
      "Epoch 29/50\n",
      "15114/15114 [==============================] - 175s 12ms/step - loss: 0.4429 - accuracy: 0.8171 - val_loss: 0.5766 - val_accuracy: 0.7958\n",
      "Epoch 30/50\n",
      "15114/15114 [==============================] - 182s 12ms/step - loss: 0.4101 - accuracy: 0.8482 - val_loss: 0.5371 - val_accuracy: 0.8265\n",
      "Epoch 31/50\n",
      "15114/15114 [==============================] - 171s 11ms/step - loss: 0.3735 - accuracy: 0.8633 - val_loss: 0.5133 - val_accuracy: 0.8386\n",
      "Epoch 32/50\n",
      "15114/15114 [==============================] - 170s 11ms/step - loss: 0.3494 - accuracy: 0.8725 - val_loss: 0.5040 - val_accuracy: 0.8386\n",
      "Epoch 33/50\n",
      "15114/15114 [==============================] - 169s 11ms/step - loss: 0.3290 - accuracy: 0.8770 - val_loss: 0.4990 - val_accuracy: 0.8392\n",
      "Epoch 34/50\n",
      "15114/15114 [==============================] - 169s 11ms/step - loss: 0.3168 - accuracy: 0.8777 - val_loss: 0.4954 - val_accuracy: 0.8418\n",
      "Epoch 35/50\n",
      "15114/15114 [==============================] - 168s 11ms/step - loss: 0.3033 - accuracy: 0.8815 - val_loss: 0.4964 - val_accuracy: 0.8423\n",
      "Epoch 36/50\n",
      "15114/15114 [==============================] - 159s 10ms/step - loss: 0.2944 - accuracy: 0.8832 - val_loss: 0.4870 - val_accuracy: 0.8418\n",
      "Epoch 37/50\n",
      "15114/15114 [==============================] - 160s 11ms/step - loss: 0.2864 - accuracy: 0.8858 - val_loss: 0.4851 - val_accuracy: 0.8466\n",
      "Epoch 38/50\n",
      "15114/15114 [==============================] - 162s 11ms/step - loss: 0.2761 - accuracy: 0.8884 - val_loss: 0.4850 - val_accuracy: 0.8497\n",
      "Epoch 39/50\n",
      "15114/15114 [==============================] - 164s 11ms/step - loss: 0.2712 - accuracy: 0.8887 - val_loss: 0.4815 - val_accuracy: 0.8519\n",
      "Epoch 40/50\n",
      "15114/15114 [==============================] - 158s 10ms/step - loss: 0.2639 - accuracy: 0.8907 - val_loss: 0.4684 - val_accuracy: 0.8529\n",
      "Epoch 41/50\n",
      "15114/15114 [==============================] - 157s 10ms/step - loss: 0.2570 - accuracy: 0.8939 - val_loss: 0.4753 - val_accuracy: 0.8545\n",
      "Epoch 42/50\n",
      "15114/15114 [==============================] - 158s 10ms/step - loss: 0.2494 - accuracy: 0.8955 - val_loss: 0.4631 - val_accuracy: 0.8561\n",
      "Epoch 43/50\n",
      "15114/15114 [==============================] - 157s 10ms/step - loss: 0.2388 - accuracy: 0.8965 - val_loss: 0.4620 - val_accuracy: 0.8577\n",
      "Epoch 44/50\n",
      "15114/15114 [==============================] - 158s 10ms/step - loss: 0.2227 - accuracy: 0.9073 - val_loss: 0.4365 - val_accuracy: 0.9016\n",
      "Epoch 45/50\n",
      "15114/15114 [==============================] - 158s 10ms/step - loss: 0.2026 - accuracy: 0.9480 - val_loss: 0.4157 - val_accuracy: 0.9085\n",
      "Epoch 46/50\n",
      "15114/15114 [==============================] - 157s 10ms/step - loss: 0.1841 - accuracy: 0.9542 - val_loss: 0.4083 - val_accuracy: 0.9127\n",
      "Epoch 47/50\n",
      "15114/15114 [==============================] - 158s 10ms/step - loss: 0.1687 - accuracy: 0.9571 - val_loss: 0.4036 - val_accuracy: 0.9095\n",
      "Epoch 48/50\n",
      "15114/15114 [==============================] - 157s 10ms/step - loss: 0.1619 - accuracy: 0.9579 - val_loss: 0.4055 - val_accuracy: 0.9122\n",
      "Epoch 49/50\n",
      "15114/15114 [==============================] - 157s 10ms/step - loss: 0.1494 - accuracy: 0.9585 - val_loss: 0.4074 - val_accuracy: 0.9138\n",
      "Epoch 50/50\n",
      "15114/15114 [==============================] - 159s 11ms/step - loss: 0.1404 - accuracy: 0.9604 - val_loss: 0.4020 - val_accuracy: 0.9095\n"
     ]
    }
   ],
   "source": [
    "history = pretext_model.fit(X_train, Y_train, \n",
    "                    epochs=50, \n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1889/1889 [==============================] - 1s 699us/step\n",
      "[[287   0   0   1   0   0   2  10   1   0   0   0]\n",
      " [  0 613   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   2   0   0   0   0   0   4]\n",
      " [  0   0   0  49   0   0   5   3   1   0   0   0]\n",
      " [  0   0   0  17   0   0   1   0   0   0   0   0]\n",
      " [  0   0   0   7   0  20   0   2   0   0   0   2]\n",
      " [  0   0   0   3   0   0 229   8   5   0   0   0]\n",
      " [  3   0   0   0   0   0   3 197   2   0   0   0]\n",
      " [  3   0   0   3   0   0   4   4 187   0   1   4]\n",
      " [  0   0   0   0   0   1   0   1   1   0   0  29]\n",
      " [  0   0   0   0   0   0   0   1   1   0  94   0]\n",
      " [  2   0   0   3   0   0   2   0   6   0   0  64]]\n",
      "Test set\n",
      "  Loss: 0.328\n",
      "  Accuracy: 0.921\n"
     ]
    }
   ],
   "source": [
    "pretext_model.save(\"author_lstm_with_pretext_results\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "accuracy = pretext_model.evaluate(X_test, Y_test)\n",
    "prediction = pretext_model.predict(X_test)\n",
    "confusion_matrix = confusion_matrix(Y_test.argmax(axis=1), prediction.argmax(axis=1))\n",
    "print(confusion_matrix)\n",
    "\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accuracy[0],accuracy[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 80, 50)            2056350   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 80, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                1212      \n",
      "=================================================================\n",
      "Total params: 2,117,962\n",
      "Trainable params: 2,117,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "callback = callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                   output_dim=embedding_dim,\n",
    "                  input_length=max_sequence_length))\n",
    "model.add(layers.SpatialDropout1D(0.2))\n",
    "\n",
    "model.add(layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15114 samples, validate on 1890 samples\n",
      "Epoch 1/20\n",
      "15114/15114 [==============================] - 96s 6ms/step - loss: 1.7024 - accuracy: 0.4209 - val_loss: 1.3779 - val_accuracy: 0.5111\n",
      "Epoch 2/20\n",
      "15114/15114 [==============================] - 98s 7ms/step - loss: 1.5640 - accuracy: 0.4645 - val_loss: 1.3729 - val_accuracy: 0.5265\n",
      "Epoch 3/20\n",
      "15114/15114 [==============================] - 92s 6ms/step - loss: 1.3066 - accuracy: 0.5369 - val_loss: 1.2581 - val_accuracy: 0.5333\n",
      "Epoch 4/20\n",
      "15114/15114 [==============================] - 92s 6ms/step - loss: 1.2282 - accuracy: 0.5498 - val_loss: 1.1527 - val_accuracy: 0.5772\n",
      "Epoch 5/20\n",
      "15114/15114 [==============================] - 92s 6ms/step - loss: 1.1698 - accuracy: 0.5689 - val_loss: 1.1254 - val_accuracy: 0.5778\n",
      "Epoch 6/20\n",
      "15114/15114 [==============================] - 92s 6ms/step - loss: 1.1209 - accuracy: 0.5779 - val_loss: 1.2443 - val_accuracy: 0.5291\n",
      "Epoch 7/20\n",
      "15114/15114 [==============================] - 93s 6ms/step - loss: 1.0462 - accuracy: 0.6178 - val_loss: 0.9375 - val_accuracy: 0.6561\n",
      "Epoch 8/20\n",
      "15114/15114 [==============================] - 93s 6ms/step - loss: 0.9082 - accuracy: 0.6794 - val_loss: 0.8218 - val_accuracy: 0.7138\n",
      "Epoch 9/20\n",
      "15114/15114 [==============================] - 94s 6ms/step - loss: 0.8114 - accuracy: 0.7154 - val_loss: 0.7375 - val_accuracy: 0.7561\n",
      "Epoch 10/20\n",
      "15114/15114 [==============================] - 92s 6ms/step - loss: 0.7076 - accuracy: 0.7606 - val_loss: 0.6861 - val_accuracy: 0.7862\n",
      "Epoch 11/20\n",
      "15114/15114 [==============================] - 92s 6ms/step - loss: 0.6208 - accuracy: 0.7969 - val_loss: 0.5917 - val_accuracy: 0.8090\n",
      "Epoch 12/20\n",
      "15114/15114 [==============================] - 92s 6ms/step - loss: 0.5258 - accuracy: 0.8348 - val_loss: 0.5260 - val_accuracy: 0.8386\n",
      "Epoch 13/20\n",
      "15114/15114 [==============================] - 92s 6ms/step - loss: 0.4426 - accuracy: 0.8624 - val_loss: 0.4613 - val_accuracy: 0.8651\n",
      "Epoch 14/20\n",
      "15114/15114 [==============================] - 93s 6ms/step - loss: 0.3790 - accuracy: 0.8833 - val_loss: 0.4099 - val_accuracy: 0.8714\n",
      "Epoch 15/20\n",
      "15114/15114 [==============================] - 92s 6ms/step - loss: 0.3250 - accuracy: 0.8992 - val_loss: 0.3711 - val_accuracy: 0.8825\n",
      "Epoch 16/20\n",
      "15114/15114 [==============================] - 92s 6ms/step - loss: 0.2512 - accuracy: 0.9224 - val_loss: 0.3410 - val_accuracy: 0.8921\n",
      "Epoch 17/20\n",
      "15114/15114 [==============================] - 92s 6ms/step - loss: 0.2009 - accuracy: 0.9359 - val_loss: 0.2967 - val_accuracy: 0.9095\n",
      "Epoch 18/20\n",
      "15114/15114 [==============================] - 92s 6ms/step - loss: 0.1597 - accuracy: 0.9477 - val_loss: 0.2892 - val_accuracy: 0.9132\n",
      "Epoch 19/20\n",
      "15114/15114 [==============================] - 1484s 98ms/step - loss: 0.1290 - accuracy: 0.9582 - val_loss: 0.2829 - val_accuracy: 0.9185\n",
      "Epoch 20/20\n",
      "15114/15114 [==============================] - 74s 5ms/step - loss: 0.1048 - accuracy: 0.9661 - val_loss: 0.2507 - val_accuracy: 0.9349\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "                    epochs=20, \n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1889/1889 [==============================] - 1s 489us/step\n",
      "[[285   0   0   1   0   5   2   7   0   0   0   1]\n",
      " [  0 613   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   5   1   0]\n",
      " [  1   0   0  43   0   3   4   5   1   0   1   0]\n",
      " [  0   0   0   2  10   4   1   1   0   0   0   0]\n",
      " [  0   0   0   0   0  25   4   2   0   0   0   0]\n",
      " [  0   0   0   1   0   7 235   0   2   0   0   0]\n",
      " [  2   0   0   1   0   1   4 196   1   0   0   0]\n",
      " [  4   0   0   0   0   3   8   0 182   0   3   6]\n",
      " [  0   0   0   0   0   0   0   0   0  31   0   1]\n",
      " [  0   0   0   1   0   0   2   0   0   0  93   0]\n",
      " [  0   0   0   0   0   0   1   1   7   0   3  65]]\n",
      "Test set\n",
      "  Loss: 0.214\n",
      "  Accuracy: 0.941\n"
     ]
    }
   ],
   "source": [
    "model.save(\"author_lstm_results\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "accuracy = model.evaluate(X_test, Y_test)\n",
    "prediction = model.predict(X_test)\n",
    "confusion_matrix = confusion_matrix(Y_test.argmax(axis=1), prediction.argmax(axis=1))\n",
    "print(confusion_matrix)\n",
    "\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accuracy[0],accuracy[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Against Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(text_train)\n",
    "X_train = vectorizer.transform(text_train)\n",
    "X_test  = vectorizer.transform(text_test)\n",
    "X_val = vectorizer.transform(text_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9603693943885853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "classifier = LogisticRegression(multi_class='multinomial', solver=\"lbfgs\")\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(classifier, X_train, label_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# classifier.fit(X_train, Y_train)\n",
    "# score = classifier.score(X_test, Y_test)\n",
    "print(\"Accuracy:\", mean(n_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10111169931180519\n",
      "[[  4   5  10   6 196   1   7   0  15  49   0   8]\n",
      " [  7 129  19  25 289   3  11  10  26  43  10  41]\n",
      " [  0   0   0   0   4   0   1   0   0   2   0   0]\n",
      " [  0   1   0   0  54   0   1   0   1   0   0   1]\n",
      " [  1   1   1   0  15   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1  26   1   0   0   0   2   0   1]\n",
      " [  1   2   3   5 198   2   2   0  10  19   0   3]\n",
      " [  1   3   1   6 171   0   3   0   5  15   0   0]\n",
      " [  0   1   5   4 124   0   4   0   9  54   0   5]\n",
      " [  0   5   0   0   2   0   1   0   0  23   0   1]\n",
      " [  0   0   2   2  85   0   0   0   1   5   0   1]\n",
      " [  0   3   1   1  29   0   1   0   4  30   0   8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "gnb = GaussianNB().fit(X_train, label_train)\n",
    "gnb_predictions = gnb.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy = gnb.score(X_test, label_test)\n",
    "print(accuracy)\n",
    "\n",
    "cm = confusion_matrix(label_test, gnb_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3462149285336157\n",
      "[[ 77  46   0  14   7   1  42  43  39   6  14  12]\n",
      " [ 63 418   0   9   2   2  33  24  29  10   5  18]\n",
      " [  1   0   0   0   1   0   3   1   0   0   1   0]\n",
      " [ 13  11   1   2   0   1  14   6   3   1   6   0]\n",
      " [  5   1   0   2   0   0   2   6   1   0   1   0]\n",
      " [  7   5   0   1   1   1   5   1   8   0   2   0]\n",
      " [ 58  29   0  14   1   1  53  30  23   5  25   6]\n",
      " [ 51  26   2   9   4   6  38  30  17   2   8  12]\n",
      " [ 35  23   1   5   1   5  29  29  37   6  20  15]\n",
      " [  4   6   0   1   0   0   2   4   4   4   0   7]\n",
      " [ 13   5   0   3   1   2  20   8  17   0  23   4]\n",
      " [ 12  14   2   0   1   1   6   8  12   6   6   9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree_model = DecisionTreeClassifier().fit(X_train, label_train)\n",
    "\n",
    "dtree_predictions = dtree_model.predict(X_test)\n",
    "accuracy = dtree_model.score(X_test, label_test)\n",
    "print(accuracy)\n",
    "\n",
    "cm = confusion_matrix(label_test, dtree_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (k-nearest-neighbors) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3065113816834304\n",
      "[[ 87 138   0   3   0   1  29  26   7   0  10   0]\n",
      " [109 433   0   3   0   1  25  30   6   0   5   1]\n",
      " [  2   3   0   0   0   0   1   1   0   0   0   0]\n",
      " [ 23  14   0   1   0   1  10   5   2   0   2   0]\n",
      " [  7   6   0   0   0   0   1   3   0   0   1   0]\n",
      " [ 13  12   0   1   0   0   0   2   1   0   2   0]\n",
      " [103  76   1   0   0   0  19  26   9   0  11   0]\n",
      " [ 73  62   0   3   0   1  20  26   9   0  11   0]\n",
      " [ 52  98   0   2   0   0  22  20   6   0   5   1]\n",
      " [  4  26   0   0   0   0   1   1   0   0   0   0]\n",
      " [ 36  25   0   0   0   0  11  14   2   0   7   1]\n",
      " [ 15  47   0   0   0   0   6   6   1   0   2   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train, label_train)\n",
    "\n",
    "accuracy = knn.score(X_test, label_test)\n",
    "print(accuracy)\n",
    "\n",
    "knn_predictions=knn.predict(X_test)\n",
    "cm = confusion_matrix(label_test, knn_predictions)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
